{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers In Neuroscience\n",
    "\n",
    "### Author: Domenick Mifsud\n",
    "### Date: 5/21/23\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial covers the following sections:\n",
    "\n",
    "1. [Introduction & Setup](#Section-1:-Introduction-&-Setup)\n",
    "\n",
    "2. [What are Transformers?](#section-1-introduction--setup)\n",
    "    <br>\n",
    "    <br> 2.1&nbsp;&nbsp;[Background](#Sec-2.1:-Background)\n",
    "    <br> 2.2&nbsp;&nbsp;[Model Architecture](#Model-Architecture)\n",
    "    <br> 2.3&nbsp;&nbsp;[Self-Attention Overview](#Self-Attention-Overview)\n",
    "    <br>\n",
    "3. [Applications to Neuroscience](#section-1-introduction--setup)\n",
    "    <br>\n",
    "    <br> 3.1&nbsp;&nbsp;[FMRI](#Background)\n",
    "    <br> 3.2&nbsp;&nbsp;[Calcium](#Model-Architecture)\n",
    "    <br> 3.3&nbsp;&nbsp;[Ephys](#Self-Attention-Overview)\n",
    "    <br>\n",
    "4. [Create a Neural Data Transformer](#Create-a-Neural-Data-Transformer)\n",
    "    <br>\n",
    "    <br> 4.1&nbsp;&nbsp;[Feed Forward Layer](#Feed-Forward-Layer)\n",
    "    <br> 4.2&nbsp;&nbsp;[Multi-head Attention Layer](#Multi-head-Attention-Layer)\n",
    "    <br> 4.3&nbsp;&nbsp;[Encoder Layer](#Encoder-Layer)\n",
    "    <br> 4.4&nbsp;&nbsp;[The Full Model](#The-Full-Model)\n",
    "    <br>\n",
    "5. [Model Training & Evaluation](#Model-Training-&-Evaluation)\n",
    "    <br>\n",
    "    <br> 5.1&nbsp;&nbsp;[Download the Data](#Download-the-Data)\n",
    "    <br> 5.2&nbsp;&nbsp;[Model Training](#Model-Training)\n",
    "    <br> 5.3&nbsp;&nbsp;[Model Evaluation](#Model-Evaluation)\n",
    "    <br>\n",
    "---\n",
    "\n",
    "## Section 1: Introduction & Setup\n",
    "\n",
    "### Introduction\n",
    "\n",
    "> This is just an example introduction. This tutorial will be about what transformers are, specifically focusing on self-attention.\n",
    "\n",
    "### Setup\n",
    "\n",
    "#### Package Installs \n",
    "**(‚ö†Ô∏è Only run this once! ‚ö†Ô∏è)**\n",
    "\n",
    "To set up your environment for the first time, uncomment (delete the `#`) and run the following code to install the neccessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Data\n",
    "**(‚ö†Ô∏è Only run this once! ‚ö†Ô∏è)**\n",
    "\n",
    "Uncomment the following lines to download the dataset into your colab notebook. We'll be using the dataset collected by Mark Churchland and first published in 2008 called the \"Maze Dataset\". It is publically available as part of the Neural Latents Benchmark contest (https://neurallatents.github.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !dandi download DANDI:000140/0.220113.0408\n",
    "# !dandi download https://dandiarchive.org/dandiset/000138\n",
    "# !mv 000140 ../../data/\n",
    "# !mv 000138 ../../data/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Package Imports\n",
    "Now run the following cells to import the required packages and set up the helper code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # For tensor operations\n",
    "import numpy as np  # For array operations\n",
    "import torch.nn as nn  # For neural network layers\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "import torch.nn.functional as F  # For functional operations\n",
    "import plotly.graph_objects as go # For 3D plotting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions\n",
    "\n",
    "These are helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot a 3D scatterplot using plotly\n",
    "def create_3d_scatterplot(data_tuples, xaxis_title, yaxis_title, zaxis_title, fig_size=(700, 500)):\n",
    "    data = [go.Scatter3d(x=[v[0]], y=[v[1]], z=[v[2]], mode='markers', name=n) for v, n in data_tuples]\n",
    "    data.append(go.Scatter3d(x=[0], y=[0], z=[0], mode='markers', marker=dict(size=2, color='black'), name='center (0,0,0)'))\n",
    "    layout_dict = dict(xaxis=dict(title=xaxis_title, range=[-1, 1]),\n",
    "                       yaxis=dict(title=yaxis_title, range=[-1, 1]),\n",
    "                       zaxis=dict(title=zaxis_title, range=[-1, 1]),\n",
    "                       camera=dict(eye=dict(x=1.3, y=-1.3, z=1.3), center=dict(x=0.065, y=0.0, z=-0.075)),\n",
    "                       aspectmode='cube')\n",
    "    layout = go.Layout(scene=layout_dict, margin=dict(l=0,r=0,b=0,t=0), width=fig_size[0], height=fig_size[1])\n",
    "    return go.Figure(data=data, layout=layout).show(config={'displayModeBar': False})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: What are Transformers?\n",
    "\n",
    "### Sec 2.1: **Background**\n",
    "\n",
    "Transformer neural networks are sequence-to-sequence models, they take in a set of inputs (or *tokens*) and return a set of outputs.\n",
    "\n",
    "They are highly parallelizable (can train models faster), as opposed to the sequential nature of previous models like RNNs and LSTMs. They have been widely used in natural language processing (NLP), but have also shown promise in many other domains, such as: computer vision üñºÔ∏è, time series modeling üìà, and even neuroscience üß†.\n",
    "\n",
    "<img src=\"./transformer_inputs.png\" alt=\"inputs\" width=\"650\"/>\n",
    "\n",
    "What makes these models so special is the way that they move information throughout the inputs... \n",
    "\n",
    "In an RNN, this would be done using a hidden state that keeps track of the important information from previously seen inputs, and updates the hidden state for each new input. The issue with this is that the model can only fit so much into it's hidden state, so eventually you will need to forget some things. \n",
    "\n",
    "In a transformer however, information is not routed through a hidden state but is directly exchanged between inputs. This can be seen in the example below, where we are trying to predict the next word in the sequence. With the RNN, we only have information from the hidden state to try and predict the next word, with the transformer however, we can pull information from any words in the sequence!\n",
    "\n",
    "<img src=\"./rnn_v_transformer.png\" alt=\"inputs\" width=\"600\"/>\n",
    "\n",
    "This routing of information across the tokens is accomplished through the use of: ***Self-Attention***, more specifically, ***Scaled Dot Product Attention***\n",
    "\n",
    "---\n",
    "\n",
    "### Sec 2.2: **Model Architecture**\n",
    "The original transformer in the Attention is all you need paper followed the encoder- decoder architectue:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Sec 2.3: **Self-Attention Overview**\n",
    "\n",
    "\n",
    "To understand how attention can \"route\" information across tokens, we need to first understand the mechanism by which the tokens interact. In the example below, the tokens are words. To feed these words into a neural network we must first convert them into numbers so the network can process them. This is accomplished through the use of *word embeddings*.\n",
    "\n",
    "Word embeddings are vectors that represent individual words. Each dimension in the vector represents how much the word relates to some abstract concept. To illustrate this, lets take 3 example words:\n",
    "\n",
    "* **`Fish`** üêü\n",
    "* **`Boat`** üö¢\n",
    "* **`Hunt`** üî´\n",
    "\n",
    "and represent them as 3D embeddings. We will manually set the dimensions to represent 3 arbitrary abstract concepts:\n",
    "\n",
    "1. Is it an **activity**?   (-1 is never, +1 is always)\n",
    "\n",
    "2. Is it closer related to the **sea** or to **land**   (-1 is sea, +1 is land)\n",
    "3. Is it related to **animals**?   (-1 is never, +1 is always)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#      [activity,  sea/land,  animals]\n",
    "fish = [0.2,       -0.8,      0.9] \n",
    "boat = [-0.2,      -0.9,      -0.1]\n",
    "hunt = [0.8,       0.9,       0.8]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our 3 word embedding vectors, lets look at them in 3d space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "displayModeBar": false,
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "fish",
         "type": "scatter3d",
         "x": [
          0.2
         ],
         "y": [
          -0.8
         ],
         "z": [
          0.9
         ]
        },
        {
         "mode": "markers",
         "name": "boat",
         "type": "scatter3d",
         "x": [
          -0.2
         ],
         "y": [
          -0.9
         ],
         "z": [
          -0.1
         ]
        },
        {
         "mode": "markers",
         "name": "hunt",
         "type": "scatter3d",
         "x": [
          0.8
         ],
         "y": [
          0.9
         ],
         "z": [
          0.8
         ]
        },
        {
         "marker": {
          "color": "black",
          "size": 2
         },
         "mode": "markers",
         "name": "center (0,0,0)",
         "type": "scatter3d",
         "x": [
          0
         ],
         "y": [
          0
         ],
         "z": [
          0
         ]
        }
       ],
       "layout": {
        "height": 500,
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "scene": {
         "aspectmode": "cube",
         "camera": {
          "center": {
           "x": 0.065,
           "y": 0,
           "z": -0.075
          },
          "eye": {
           "x": 1.3,
           "y": -1.3,
           "z": 1.3
          }
         },
         "xaxis": {
          "range": [
           -1,
           1
          ],
          "title": {
           "text": "Activity"
          }
         },
         "yaxis": {
          "range": [
           -1,
           1
          ],
          "title": {
           "text": "Sea vs Land"
          }
         },
         "zaxis": {
          "range": [
           -1,
           1
          ],
          "title": {
           "text": "Animals"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 700
       }
      },
      "text/html": [
       "<div>                            <div id=\"de114e08-1f1d-4715-b5ab-8f2e389d0919\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"de114e08-1f1d-4715-b5ab-8f2e389d0919\")) {                    Plotly.newPlot(                        \"de114e08-1f1d-4715-b5ab-8f2e389d0919\",                        [{\"mode\":\"markers\",\"name\":\"fish\",\"x\":[0.2],\"y\":[-0.8],\"z\":[0.9],\"type\":\"scatter3d\"},{\"mode\":\"markers\",\"name\":\"boat\",\"x\":[-0.2],\"y\":[-0.9],\"z\":[-0.1],\"type\":\"scatter3d\"},{\"mode\":\"markers\",\"name\":\"hunt\",\"x\":[0.8],\"y\":[0.9],\"z\":[0.8],\"type\":\"scatter3d\"},{\"marker\":{\"color\":\"black\",\"size\":2},\"mode\":\"markers\",\"name\":\"center (0,0,0)\",\"x\":[0],\"y\":[0],\"z\":[0],\"type\":\"scatter3d\"}],                        {\"height\":500,\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":0},\"scene\":{\"aspectmode\":\"cube\",\"camera\":{\"center\":{\"x\":0.065,\"y\":0.0,\"z\":-0.075},\"eye\":{\"x\":1.3,\"y\":-1.3,\"z\":1.3}},\"xaxis\":{\"range\":[-1,1],\"title\":{\"text\":\"Activity\"}},\"yaxis\":{\"range\":[-1,1],\"title\":{\"text\":\"Sea vs Land\"}},\"zaxis\":{\"range\":[-1,1],\"title\":{\"text\":\"Animals\"}}},\"width\":700,\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"displayModeBar\": false, \"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('de114e08-1f1d-4715-b5ab-8f2e389d0919');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_tuples = [(fish, 'fish'), (boat, 'boat'), (hunt, 'hunt')]\n",
    "create_3d_scatterplot(data_tuples, 'Activity', 'Sea vs Land', 'Animals')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visually see that boat and fish are closely related in this space!\n",
    "\n",
    "A cool example (which allows us to look at different low-d representations of high-d embeddings) is this: https://projector.tensorflow.org/\n",
    "\n",
    "\n",
    "Now lets take a look at the **dot product**, or how self-attention quantifies the similarity between these vectors:\n",
    "\n",
    "$$ A \\cdot B = \\sum_{i=1}^{n} a_{i} b_{i} $$\n",
    "\n",
    "***Should I convert this part to be a student activity?***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between fish and boat: 0.59\n",
      "Similarity between fish and hunt: 0.16\n",
      "Similarity between boat and hunt: -1.05\n"
     ]
    }
   ],
   "source": [
    "print(f'Similarity between fish and boat: {np.dot(fish, boat):.2f}')\n",
    "print(f'Similarity between fish and hunt: {np.dot(fish, hunt):.2f}')\n",
    "print(f'Similarity between boat and hunt: {np.dot(boat, hunt):.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it correctly found `fish` and `boat` highly related! It also determined that `fish` and `hunt` are more closely related than `boat` and `hunt`.\n",
    "\n",
    "> TODO: add transition into actual self attention\n",
    "\n",
    "#### Self Attention Formula\n",
    "\n",
    "The actual formula for SA is...\n",
    "\n",
    "$$ Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V $$\n",
    "\n",
    "go into K, Q, V as a filing system analogy...\n",
    "\n",
    "**(‚ö†Ô∏è Need to recreate these images! ‚ö†Ô∏è)**\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/gpt2/self-attention-example-folders-3.png\" alt=\"inputs\" width=\"650\"/>\n",
    "<br></br>After Attention & Softmax:<br></br>\n",
    "<img src=\"https://jalammar.github.io/images/gpt2/self-attention-example-folders-scores-3.png\" alt=\"inputs\" width=\"650\"/>\n",
    "\n",
    "***Should this have a section where they project the embeddings created earlier into multiple 2-d embeddings (MHA example)??***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that I need to incorperate A section about "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Section 3: Create a Neural Data Transformer\n",
    "\n",
    "In this section we will be creating a simplified version of the Neural Data Transformer ([pdf](https://arxiv.org/pdf/2108.01210.pdf)) ([repo](https://github.com/snel-repo/neural-data-transformers)), training it on data from the Nerual Latents Benchmark, and ...\n",
    "\n",
    "...\n",
    "\n",
    "# !!!\n",
    "\n",
    "...\n",
    "\n",
    "##### ***Introductory Terms***:\n",
    "\n",
    "* ***[Subclass](https://uwpce-pythoncert.github.io/ProgrammingInPython/modules/SubclassingAndInheritance.html)***: An object that gets to use all the functions defined in its \"superclass\". By creating a subclass you are saying: this Object is a *superclass*, but heres even more things that it can do that *superclass* can't.\n",
    "\n",
    "* ***[Batch](https://www.linkedin.com/advice/3/what-benefits-drawbacks-batch-processing-ml-skills-batch-processing)***: A bunch of inputs being processed at once to speed up neural network training. Think of it like like an airport shuttle, if multiple people need to make the same trip it makes sense to take everyone together!\n",
    "\n",
    "* ***[Linear Layer](https://pytorch.org/docs/stable/nn.html#linear-layers)***: A.K.A. a Fully-Connected Layer, is a matrix multiplication on the incoming data with a learned \"weight\" matrix and then addition with a learned \"bias\" term. \n",
    "\n",
    "* ***[Normalization](https://pytorch.org/docs/stable/nn.html#normalization-layers)***: is a technique that adjusts the inputs to make their distribution more uniform. This helps the model learn more efficiently as it ensures all inputs are on a similar scale. \n",
    "    * Transformers often use [Layer Normalization](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html) (LayerNorm), where the mean and variance are computed independently for each input across all its features, adjusting and scaling the activations within the current layer. This is different from other normalization techniques such as Batch Normalization, which computes a single mean and variance for the entire batch.\n",
    "    <br></br>\n",
    "* ***[Dropout](https://pytorch.org/docs/stable/nn.html#dropout-layers)***: is a \"regularization\" technique where a proportion feature in the inputs are randomly \"dropped out\" or set to zero during training. This helps keep the features from relying on the presence of particular other features and is forced to learn more robust features that are useful in conjunction with many different random subsets of the other features. This improves model robustness and the ability to generalize to unseen data.\n",
    "\n",
    "##### ***Understanding the PyTorch Docs***:\n",
    "\n",
    "As an example, here is the first line from the [linear layer docs](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear):\n",
    "```python\n",
    "    class torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
    "```\n",
    "In the above line, the parameters are the items in the comma seperated list within the parentheses () after `torch.nn.Linear`.\n",
    "<br></br>\n",
    "A linear layer object would be created by providing the class with parameters in the order requested. The parameters that have the equal sign next to them do *not* need to be provided becuase the equal sign means, \"here is what the value will be if you dont give me anything\". \n",
    "<br>\n",
    "\n",
    "To understand more about the parameters it is requesting, look for the unordered list under the bold text: \"**Parameters:**\"\n",
    "\n",
    "Here is how you would create a object from the above class that takes in a vector of with 3 dimensions and outputs a vector with 4 dimensions:\n",
    "```python\n",
    "    in_dim = 3\n",
    "    out_dim = 4\n",
    "    self.example_layer = nn.Linear(in_dim, out_dim)\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Sec 3.1: **Feed Forward Layer**\n",
    "\n",
    "The [Feed-Forward Network](https://en.wikipedia.org/wiki/Feedforward_neural_network) (FFN) is a crucial part of the transformer architecture. It is applied independently to each token in the sequence, so this operation is highly parrallelizable (speeds up training and execution of the model because you can do it all tokens in one operation). The FFN consists of two linear layers and a non-linearity in between. It is essential for introducing non-linearity to the system and allowing the model to learn more complex representations. Despite its name, it doesn't carry information forward in terms of sequential data but instead contributes to the transformation of the input data within each individual layer. \n",
    "\n",
    "* Transformers often use the [rectified linear unit](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) (ReLU) function as their choice of non-linearity, which just sets negative values to 0. Simple huh! \n",
    "\n",
    "    <img src=\"https://pytorch.org/docs/stable/_images/ReLU.png\" alt=\"inputs\" width=\"400\"/>\n",
    "\n",
    "##### **Exercise**\n",
    "Now let's implement the FFN using PyTorch. You will need to create a class called FeedForwardNetwork, which is a subclass of nn.Module. \n",
    "\n",
    "**You need to provide the class with code to do two things:**\n",
    "1. First to initialize the various PyTorch layers/functions to the requested sizes within the `__init__` method of your class.\n",
    "2. Then to transform the incoming using those layers you created within the `forward` method of your class.\n",
    "\n",
    "**The FFN should consist of** two linear layers ([nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)), a normalization layer ([nn.LayerNorm](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#layernorm)), a dropout layer ([nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#dropout)), and a non-linear activation function ([nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)). \n",
    "* The LayerNorm should be named `self.norm` \n",
    "    * it will normalize the data with shape `input_dim`\n",
    "    <br></br>\n",
    "* The first linear layer should be named `self.linear1`\n",
    "    * it will transform the input dimensions from `input_dim` to `hidden_dim`\n",
    "    <br></br>\n",
    "* The ReLU function should be named `self.relu`\n",
    "<br></br>\n",
    "* The dropout layer should be named `self.dropout` \n",
    "    * it will have a `dropout_p` probability of an element to be zeroed\n",
    "    <br></br>\n",
    "* The second linear layer should be named `self.linear2` \n",
    "    * it will transform the input dimensions from `hidden_dim` to `input_dim`\n",
    "    <br></br>\n",
    "\n",
    "! ***MAKE SURE YOU USE THE VARIABLE NAMES DEFINED ABOVE*** !\n",
    "\n",
    "Next, within the forward method, you are to define the forward pass for this network. \n",
    "<br>\n",
    "**This method should:** \n",
    "1. Pass the input x through the LayerNorm\n",
    "2. Pass the result through the first linear layer\n",
    "3. Pass the result through the ReLU activation\n",
    "5. Pass the result through the dropout layer\n",
    "4. Pass the result through the second linear layer\n",
    "\n",
    "Use the following code snippet as your starting point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_p):\n",
    "        super().__init__()\n",
    "        # TODO: Define the LayerNorm\n",
    "        # TODO: Define the first linear layer\n",
    "        # TODO: Define the ReLU activation function\n",
    "        # TODO: Define the dropout layer\n",
    "        # TODO: Define the second linear layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x) # pass through LayerNorm\n",
    "        # TODO: Define the rest of the forward pass\n",
    "        return out # return the output of the second linear layer\n",
    "    \n",
    "class FeedForwardLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_p):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_dim)\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.linear2 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x) # pass through LayerNorm\n",
    "        x = self.linear1(x) # pass through first linear layer\n",
    "        x = self.relu(x) # pass through ReLU activation function\n",
    "        x = self.dropout(x) # pass through dropout layer\n",
    "        out = self.linear2(x) # pass through second linear layer\n",
    "        return out # return the output of the second linear layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you finish creating the class, run the cell and continue to the next section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Sec 3.2: **Multi-head Attention Layer**\n",
    "\n",
    "The [Feed-Forward Network](https://en.wikipedia.org/wiki/Feedforward_neural_network) (FFN) is a crucial part of the transformer architecture. It is applied independently to each token in the sequence, so this operation is highly parrallelizable (speeds up training and execution of the model because you can do it all tokens in one operation). The FFN consists of two linear layers and a non-linearity in between. It is essential for introducing non-linearity to the system and allowing the model to learn more complex representations. Despite its name, it doesn't carry information forward in terms of sequential data but instead contributes to the transformation of the input data within each individual layer. \n",
    "\n",
    "* Transformers often use the [rectified linear unit](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) (ReLU) function as their choice of non-linearity, which just sets negative values to 0. Simple huh! \n",
    "\n",
    "##### **Exercise**\n",
    "Now let's implement the FFN using PyTorch. You will need to create a class called FeedForwardNetwork, which is a subclass of nn.Module. \n",
    "\n",
    "**You need to provide the class with code to do two things:**\n",
    "1. First to initialize the various PyTorch layers/functions to the requested sizes within the `__init__` method of your class.\n",
    "2. Then to transform the incoming using those layers you created within the `forward` method of your class.\n",
    "\n",
    "**The FFN should consist of** two linear layers ([nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)), a normalization layer ([nn.LayerNorm](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#layernorm)), a dropout layer ([nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#dropout)), and a non-linear activation function ([nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)). \n",
    "* The LayerNorm should be named `self.norm` \n",
    "    * it will normalize the data with shape `input_dim`\n",
    "    <br></br>\n",
    "* The first linear layer should be named `self.linear1`\n",
    "    * it will transform the input dimensions from `input_dim` to `hidden_dim`\n",
    "    <br></br>\n",
    "* The ReLU function should be named `self.relu`\n",
    "<br></br>\n",
    "* The dropout layer should be named `self.dropout` \n",
    "    * it will have a `dropout_p` probability of an element to be zeroed\n",
    "    <br></br>\n",
    "* The second linear layer should be named `self.linear2` \n",
    "    * it will transform the input dimensions from `hidden_dim` to `input_dim`\n",
    "    <br></br>\n",
    "\n",
    "\n",
    "! ***MAKE SURE YOU USE THE VARIABLE NAMES DEFINED ABOVE*** !\n",
    "\n",
    "Next, within the forward method, you are to define the forward pass for this network. \n",
    "<br>\n",
    "**This method should:** \n",
    "1. Pass the input x through the LayerNorm\n",
    "2. Pass the result through the first linear layer\n",
    "3. Pass the result through the ReLU activation\n",
    "5. Pass the result through the dropout layer\n",
    "4. Pass the result through the second linear layer\n",
    "\n",
    "Use the following code snippet as your starting point:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, head_dims, dropout_p):\n",
    "        super().__init__()\n",
    "        self.head_dims = head_dims\n",
    "        self.num_heads = num_heads\n",
    "        self.all_head_dims = head_dims * num_heads\n",
    "\n",
    "        self.norm = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "        self.linear_q = nn.Linear(input_dim, self.all_head_dims)\n",
    "        self.linear_k = nn.Linear(input_dim, self.all_head_dims)\n",
    "        self.linear_v = nn.Linear(input_dim, self.all_head_dims)\n",
    "\n",
    "        self.linear_out = nn.Linear(self.all_head_dims, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, seq_len, d_model)\n",
    "        batch_size, seq_len, input_dim = x.size()\n",
    "\n",
    "        # 1) Pass the input through the LayerNorm\n",
    "        x = self.norm(x)\n",
    "\n",
    "        # 1) Pass the input through the linear layers to get the queries, keys, and values.\n",
    "        query = self.linear_q(x)\n",
    "        key = self.linear_k(x)\n",
    "        value = self.linear_v(x)\n",
    "\n",
    "        # 2) Reshape the queries, keys, and values to shape: \n",
    "        #   (seq_len, batch_size, self.num_heads, self.head_dims)\n",
    "        split_shape = (batch_size, seq_len, self.num_heads, self.head_dims)\n",
    "        query = query.view(*split_shape).transpose(0, 1)\n",
    "        key = key.view(*split_shape).transpose(0, 1)\n",
    "        value = value.view(*split_shape).transpose(0, 1)\n",
    "\n",
    "        # 4) Pass the queries, keys, and values through the attention function\n",
    "        attn_scores = torch.matmul(query, key.T)\n",
    "        attn_scores /= torch.sqrt(self.head_dims)\n",
    "        attn = F.softmax(attn_scores, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "        x = torch.matmul(attn, value) # shape: (batch_size * num_heads, seq_len, head_dims)\n",
    "\n",
    "        # 5) Swap seq_len and batch_size * num_heads dimensions\n",
    "        x = x.transpose(0, 1).contiguous()  # shape: (seq_len, batch_size * num_heads, head_dims)\n",
    "\n",
    "        # 6) Prepare data for final linear layer\n",
    "        x = x.view(seq_len * batch_size, self.all_head_dims) # shape: (seq_len * batch_size, self.all_head_dims)\n",
    "\n",
    "        # 7) Pass the output through the final linear layer\n",
    "        x = self.linear_out(x)  # shape: (seq_len * batch_size, input_dim)\n",
    "\n",
    "        # 8) Reshape the output back to (batch_size, seq_len, input_dim)\n",
    "        x = x.view(batch_size, seq_len, input_dim)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Sec 3.3: **Encoder Layer**\n",
    "\n",
    "***Have them fill out some parts of the encoder based on diagrams / formulas / instructions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, head_dims, ffn_dim, mha_dropout_p, ffn_dropout_p):\n",
    "        super().__init__()\n",
    "        self.MHA = MultiHeadAttention(input_dim, num_heads, head_dims, mha_dropout_p)\n",
    "        self.FFN = FeedForwardLayer(input_dim, ffn_dim, ffn_dropout_p)\n",
    "\n",
    "        self.post_mha_dropout = nn.Dropout(mha_dropout_p)\n",
    "        self.post_ffn_dropout = nn.Dropout(ffn_dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.MHA(x)\n",
    "        x = self.post_mha_dropout(x)\n",
    "        x = x + residual\n",
    "\n",
    "        residual = x\n",
    "        x = self.FFN(x)\n",
    "        x = self.post_ffn_dropout(x)\n",
    "        x = x + residual\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Sec 3.4: **The Full Model**\n",
    "\n",
    "No student section, puts all layers together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralDataTransformer(nn.Module):\n",
    "    def __init__(self, config_dict):\n",
    "    # def __init__(self, n_layers, n_electrodes, factor_dim, num_heads, head_dims, ffn_dim, mha_dropout_p, ffn_dropout_p):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.ModuleList([EncoderLayer(**config_dict) for _ in range(config_dict['n_layers'])])\n",
    "        self.readin = nn.Linear(config_dict['n_electrodes'], config_dict['factor_dim'])\n",
    "        self.readout = nn.Linear(config_dict['factor_dim'], config_dict['n_electrodes'])\n",
    "\n",
    "        self.norm = nn.LayerNorm(config_dict['input_dim'])\n",
    "        self.post_readin_dropout = nn.Dropout(config_dict['post_readin_dropout_p'])\n",
    "        self.post_encoder_dropout = nn.Dropout(config_dict['post_encoder_dropout_p'])\n",
    "\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([config_dict['factor_dim']]))\n",
    "        self.classifier = nn.PoissonNLLLoss(reduction='none')\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(config_dict['seq_len'], config_dict['factor_dim']))\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        x = self.readin(x)\n",
    "\n",
    "        x = self.post_readin_dropout(x)\n",
    "\n",
    "        x *= self.scale\n",
    "\n",
    "        x = x + self.pos_embedding\n",
    "\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "\n",
    "        x = self.post_encoder_dropout(x)\n",
    "\n",
    "        x = self.readout(x)\n",
    "\n",
    "        if labels == None: \n",
    "            return x\n",
    "        \n",
    "        loss = self.classifier(x, labels)\n",
    "\n",
    "        masked_loss = loss[labels != -100]\n",
    "\n",
    "        masked_loss = masked_loss.mean()\n",
    "\n",
    "        return masked_loss, x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Model Training & Evaluation\n",
    "\n",
    "### Sec 4.1: **Process the Data**\n",
    "\n",
    "Using the MC Maze small, and predefined data functions break the NWB down (trialized) and get the train, val, test tensors.\n",
    "\n",
    "Functions needed: NWB processing\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Sec 4.2: **Model Training**\n",
    "\n",
    "load in pretrained parameters into the model that they just created.\n",
    "\n",
    "***Have them fill out some parts of the training loop***\n",
    "\n",
    "have the model finetune for X epochs.\n",
    "\n",
    "Functions needed: Training function?\n",
    "\n",
    "---\n",
    "\n",
    "### Sec 4.3: **Model Evaluation**\n",
    "\n",
    "***Have them fill out some parts of the model eval setup***\n",
    "\n",
    "Show a PCA of the rates vs the smoothed spikes... aligned w/ trial start? movement may be too much \n",
    "\n",
    "Decoding of smoothed vs rates \n",
    "\n",
    "Functions needed: PCA, plotting for PCA, deocding\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
